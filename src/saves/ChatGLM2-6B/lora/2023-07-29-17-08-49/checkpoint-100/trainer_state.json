{
  "best_metric": 1.466796875,
  "best_model_checkpoint": "saves\\ChatGLM2-6B\\lora\\2023-07-29-17-08-49\\checkpoint-100",
  "epoch": 5.555555555555555,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.28,
      "learning_rate": 2.998572332372787e-05,
      "loss": 2.1981,
      "step": 5
    },
    {
      "epoch": 0.56,
      "learning_rate": 2.9942920471376185e-05,
      "loss": 1.9668,
      "step": 10
    },
    {
      "epoch": 0.83,
      "learning_rate": 2.9871672920607158e-05,
      "loss": 1.9456,
      "step": 15
    },
    {
      "epoch": 1.11,
      "learning_rate": 2.977211629518312e-05,
      "loss": 1.808,
      "step": 20
    },
    {
      "epoch": 1.39,
      "learning_rate": 2.9644440106799003e-05,
      "loss": 1.6802,
      "step": 25
    },
    {
      "epoch": 1.67,
      "learning_rate": 2.9488887394336025e-05,
      "loss": 1.6849,
      "step": 30
    },
    {
      "epoch": 1.94,
      "learning_rate": 2.9305754261223403e-05,
      "loss": 1.6529,
      "step": 35
    },
    {
      "epoch": 2.22,
      "learning_rate": 2.9095389311788626e-05,
      "loss": 1.6524,
      "step": 40
    },
    {
      "epoch": 2.5,
      "learning_rate": 2.8858192987669303e-05,
      "loss": 1.5355,
      "step": 45
    },
    {
      "epoch": 2.78,
      "learning_rate": 2.8594616805549752e-05,
      "loss": 1.4787,
      "step": 50
    },
    {
      "epoch": 3.06,
      "learning_rate": 2.8305162497673325e-05,
      "loss": 1.3139,
      "step": 55
    },
    {
      "epoch": 3.33,
      "learning_rate": 2.7990381056766583e-05,
      "loss": 1.3726,
      "step": 60
    },
    {
      "epoch": 3.61,
      "learning_rate": 2.7650871687193287e-05,
      "loss": 1.1112,
      "step": 65
    },
    {
      "epoch": 3.89,
      "learning_rate": 2.728728066433488e-05,
      "loss": 1.4439,
      "step": 70
    },
    {
      "epoch": 4.17,
      "learning_rate": 2.6900300104368527e-05,
      "loss": 1.1354,
      "step": 75
    },
    {
      "epoch": 4.44,
      "learning_rate": 2.649066664678467e-05,
      "loss": 1.1461,
      "step": 80
    },
    {
      "epoch": 4.72,
      "learning_rate": 2.605916005215186e-05,
      "loss": 0.9645,
      "step": 85
    },
    {
      "epoch": 5.0,
      "learning_rate": 2.5606601717798212e-05,
      "loss": 1.0927,
      "step": 90
    },
    {
      "epoch": 5.28,
      "learning_rate": 2.5133853114234907e-05,
      "loss": 0.9793,
      "step": 95
    },
    {
      "epoch": 5.56,
      "learning_rate": 2.464181414529809e-05,
      "loss": 1.0341,
      "step": 100
    },
    {
      "epoch": 5.56,
      "eval_loss": 1.466796875,
      "eval_runtime": 0.4035,
      "eval_samples_per_second": 19.827,
      "eval_steps_per_second": 2.478,
      "step": 100
    }
  ],
  "max_steps": 360,
  "num_train_epochs": 20,
  "total_flos": 378169615908864.0,
  "trial_name": null,
  "trial_params": null
}
